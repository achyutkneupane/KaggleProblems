{
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.13",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "sourceId": 5407,
     "databundleVersionId": 868283,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30732,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook",
   "isGpuEnabled": false
  }
 },
 "nbformat_minor": 5,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "markdown",
   "source": "Importing the necessary libraries:\n\n- `tensorflow_decision_forests` for the Random Forest model\n- `pandas` for data manipulation\n- `numpy` for numerical operations",
   "metadata": {},
   "id": "3084be9ecb760e4d"
  },
  {
   "cell_type": "code",
   "source": [
    "import tensorflow_decision_forests as tfdf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-06-26T16:01:16.774199Z",
     "iopub.execute_input": "2024-06-26T16:01:16.775383Z",
     "iopub.status.idle": "2024-06-26T16:01:21.526763Z",
     "shell.execute_reply.started": "2024-06-26T16:01:16.775333Z",
     "shell.execute_reply": "2024-06-26T16:01:21.525554Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-06-27T16:02:33.662749Z",
     "start_time": "2024-06-27T16:02:31.606071Z"
    }
   },
   "id": "7468f3ea9736958f",
   "outputs": [],
   "execution_count": 113
  },
  {
   "cell_type": "markdown",
   "source": "First, we load the dataset and remove the `Id` column since it is not useful for the model.",
   "metadata": {},
   "id": "c462d1e612c128de"
  },
  {
   "cell_type": "code",
   "source": [
    "# train_file_path = \"/kaggle/input/house-prices-advanced-regression-techniques/train.csv\"\n",
    "# test_file_path = \"/kaggle/input/house-prices-advanced-regression-techniques/test.csv\"\n",
    "\n",
    "train_file_path = \"data/train.csv\"\n",
    "test_file_path = \"data/test.csv\""
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-06-26T16:01:21.528919Z",
     "iopub.execute_input": "2024-06-26T16:01:21.529537Z",
     "iopub.status.idle": "2024-06-26T16:01:21.567692Z",
     "shell.execute_reply.started": "2024-06-26T16:01:21.529503Z",
     "shell.execute_reply": "2024-06-26T16:01:21.566420Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-06-27T16:02:33.743280Z",
     "start_time": "2024-06-27T16:02:33.673209Z"
    }
   },
   "id": "d2f0f0f098f8a46a",
   "outputs": [],
   "execution_count": 114
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-27T16:02:33.877006Z",
     "start_time": "2024-06-27T16:02:33.748770Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dataset_df = pd.read_csv(train_file_path)\n",
    "dataset_df = dataset_df.drop('Id', axis=1)"
   ],
   "id": "c5ac1d6d8ceac719",
   "outputs": [],
   "execution_count": 115
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-27T16:02:33.896605Z",
     "start_time": "2024-06-27T16:02:33.881608Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dataset_df.drop(\n",
    "    dataset_df[(dataset_df[\"GrLivArea\"] > 4000) & (dataset_df[\"SalePrice\"] < 300000)].index,\n",
    "    inplace=True)"
   ],
   "id": "691b036e786232a4",
   "outputs": [],
   "execution_count": 116
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-27T16:02:33.913824Z",
     "start_time": "2024-06-27T16:02:33.902180Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# dataset_df[\"LotAreaCut\"] = pd.qcut(dataset_df.LotArea, 10)\n",
    "# dataset_df['LotFrontage'] = dataset_df.groupby(['LotAreaCut', 'Neighborhood'])['LotFrontage'].transform(\n",
    "#     lambda x: x.fillna(x.median()))\n",
    "# dataset_df['LotFrontage'] = dataset_df.groupby(['LotAreaCut'])['LotFrontage'].transform(lambda x: x.fillna(x.median()))"
   ],
   "id": "6a7a70953b65109d",
   "outputs": [],
   "execution_count": 117
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-27T16:02:33.934284Z",
     "start_time": "2024-06-27T16:02:33.919169Z"
    }
   },
   "cell_type": "code",
   "source": [
    "area_cols = [\"MasVnrArea\", \"BsmtUnfSF\", \"TotalBsmtSF\", \"GarageCars\", \"BsmtFinSF2\", \"BsmtFinSF1\", \"GarageArea\"]\n",
    "for col in area_cols:\n",
    "    dataset_df[col].fillna(0, inplace=True)"
   ],
   "id": "6308a8abe8791086",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_8/s86gthys1d7dsy7_0r3l3f_m0000gn/T/ipykernel_71761/1906549421.py:3: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  dataset_df[col].fillna(0, inplace=True)\n"
     ]
    }
   ],
   "execution_count": 118
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-27T16:02:33.954966Z",
     "start_time": "2024-06-27T16:02:33.938870Z"
    }
   },
   "cell_type": "code",
   "source": [
    "feature_cols = [\"PoolQC\", \"MiscFeature\", \"Alley\", \"Fence\", \"FireplaceQu\", \"GarageQual\", \"GarageCond\", \"GarageFinish\",\n",
    "                \"GarageYrBlt\", \"GarageType\", \"BsmtExposure\", \"BsmtCond\", \"BsmtQual\", \"BsmtFinType2\", \"BsmtFinType1\",\n",
    "                \"MasVnrType\"]\n",
    "for col in feature_cols:\n",
    "    dataset_df[col].fillna(0, inplace=True)"
   ],
   "id": "755447b03d9c01d9",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_8/s86gthys1d7dsy7_0r3l3f_m0000gn/T/ipykernel_71761/698046458.py:5: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  dataset_df[col].fillna(0, inplace=True)\n"
     ]
    }
   ],
   "execution_count": 119
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-27T16:02:33.978811Z",
     "start_time": "2024-06-27T16:02:33.956942Z"
    }
   },
   "cell_type": "code",
   "source": [
    "number_cols = [\"MSSubClass\", \"BsmtFullBath\", \"BsmtHalfBath\", \"HalfBath\", \"BedroomAbvGr\", \"KitchenAbvGr\", \"MoSold\",\n",
    "               \"YrSold\", \"YearBuilt\", \"YearRemodAdd\", \"LowQualFinSF\", \"GarageYrBlt\"]\n",
    "for col in number_cols:\n",
    "    dataset_df[col] = dataset_df[col].astype(str)"
   ],
   "id": "178578f2c5e378c9",
   "outputs": [],
   "execution_count": 120
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-27T16:02:34.145993Z",
     "start_time": "2024-06-27T16:02:33.981517Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def map_values(dataset):\n",
    "    dataset[\"MSSubClass\"] = dataset.MSSubClass.map({'180': 1,\n",
    "                                                    '30': 2, '45': 2,\n",
    "                                                    '190': 3, '50': 3, '90': 3,\n",
    "                                                    '85': 4, '40': 4, '160': 4,\n",
    "                                                    '70': 5, '20': 5, '75': 5, '80': 5, '150': 5,\n",
    "                                                    '120': 6, '60': 6})\n",
    "\n",
    "    dataset[\"MSZoning\"] = dataset.MSZoning.map({'C (all)': 1, 'RH': 2, 'RM': 2, 'RL': 3, 'FV': 4})\n",
    "\n",
    "    dataset[\"Neighborhood\"] = dataset.Neighborhood.map({'MeadowV': 1,\n",
    "                                                        'IDOTRR': 2, 'BrDale': 2,\n",
    "                                                        'OldTown': 3, 'Edwards': 3, 'BrkSide': 3,\n",
    "                                                        'Sawyer': 4, 'Blueste': 4, 'SWISU': 4, 'NAmes': 4,\n",
    "                                                        'NPkVill': 5, 'Mitchel': 5,\n",
    "                                                        'SawyerW': 6, 'Gilbert': 6, 'NWAmes': 6,\n",
    "                                                        'Blmngtn': 7, 'CollgCr': 7, 'ClearCr': 7, 'Crawfor': 7,\n",
    "                                                        'Veenker': 8, 'Somerst': 8, 'Timber': 8,\n",
    "                                                        'StoneBr': 9,\n",
    "                                                        'NoRidge': 10, 'NridgHt': 10})\n",
    "\n",
    "    dataset[\"Condition1\"] = dataset.Condition1.map({'Artery': 1,\n",
    "                                                    'Feedr': 2, 'RRAe': 2,\n",
    "                                                    'Norm': 3, 'RRAn': 3,\n",
    "                                                    'PosN': 4, 'RRNe': 4,\n",
    "                                                    'PosA': 5, 'RRNn': 5})\n",
    "\n",
    "    dataset[\"BldgType\"] = dataset.BldgType.map({'2fmCon': 1, 'Duplex': 1, 'Twnhs': 1, '1Fam': 2, 'TwnhsE': 2})\n",
    "\n",
    "    dataset[\"HouseStyle\"] = dataset.HouseStyle.map({'1.5Unf': 1,\n",
    "                                                    '1.5Fin': 2, '2.5Unf': 2, 'SFoyer': 2,\n",
    "                                                    '1Story': 3, 'SLvl': 3,\n",
    "                                                    '2Story': 4, '2.5Fin': 4})\n",
    "\n",
    "    dataset[\"Exterior1st\"] = dataset.Exterior1st.map({'BrkComm': 1,\n",
    "                                                      'AsphShn': 2, 'CBlock': 2, 'AsbShng': 2,\n",
    "                                                      'WdShing': 3, 'Wd Sdng': 3, 'MetalSd': 3, 'Stucco': 3,\n",
    "                                                      'HdBoard': 3,\n",
    "                                                      'BrkFace': 4, 'Plywood': 4,\n",
    "                                                      'VinylSd': 5,\n",
    "                                                      'CemntBd': 6,\n",
    "                                                      'Stone': 7, 'ImStucc': 7})\n",
    "\n",
    "    dataset[\"MasVnrType\"] = dataset.MasVnrType.map({'BrkCmn': 1, 'None': 1, 'BrkFace': 2, 'Stone': 3})\n",
    "\n",
    "    dataset[\"ExterQual\"] = dataset.ExterQual.map({'Fa': 1, 'TA': 2, 'Gd': 3, 'Ex': 4})\n",
    "\n",
    "    dataset[\"Foundation\"] = dataset.Foundation.map({'Slab': 1,\n",
    "                                                    'BrkTil': 2, 'CBlock': 2, 'Stone': 2,\n",
    "                                                    'Wood': 3, 'PConc': 4})\n",
    "\n",
    "    dataset[\"BsmtQual\"] = dataset.BsmtQual.map({'Fa': 2, 'None': 1, 'TA': 3, 'Gd': 4, 'Ex': 5})\n",
    "\n",
    "    dataset[\"BsmtExposure\"] = dataset.BsmtExposure.map({'None': 1, 'No': 2, 'Av': 3, 'Mn': 3, 'Gd': 4})\n",
    "\n",
    "    dataset[\"Heating\"] = dataset.Heating.map({'Floor': 1, 'Grav': 1, 'Wall': 2, 'OthW': 3, 'GasW': 4, 'GasA': 5})\n",
    "\n",
    "    dataset[\"HeatingQC\"] = dataset.HeatingQC.map({'Po': 1, 'Fa': 2, 'TA': 3, 'Gd': 4, 'Ex': 5})\n",
    "\n",
    "    dataset[\"KitchenQual\"] = dataset.KitchenQual.map({'Fa': 1, 'TA': 2, 'Gd': 3, 'Ex': 4})\n",
    "\n",
    "    dataset[\"Functional\"] = dataset.Functional.map(\n",
    "        {'Maj2': 1, 'Maj1': 2, 'Min1': 2, 'Min2': 2, 'Mod': 2, 'Sev': 2, 'Typ': 3})\n",
    "\n",
    "    dataset[\"FireplaceQu\"] = dataset.FireplaceQu.map({'None': 1, 'Po': 1, 'Fa': 2, 'TA': 3, 'Gd': 4, 'Ex': 5})\n",
    "\n",
    "    dataset[\"GarageType\"] = dataset.GarageType.map({'CarPort': 1, 'None': 1,\n",
    "                                                    'Detchd': 2,\n",
    "                                                    '2Types': 3, 'Basment': 3,\n",
    "                                                    'Attchd': 4, 'BuiltIn': 5})\n",
    "\n",
    "    dataset[\"GarageFinish\"] = dataset.GarageFinish.map({'None': 1, 'Unf': 2, 'RFn': 3, 'Fin': 4})\n",
    "\n",
    "    dataset[\"PavedDrive\"] = dataset.PavedDrive.map({'N': 1, 'P': 2, 'Y': 3})\n",
    "\n",
    "    dataset[\"SaleType\"] = dataset.SaleType.map({'COD': 1, 'ConLD': 1, 'ConLI': 1, 'ConLw': 1, 'Oth': 1, 'WD': 1,\n",
    "                                                'CWD': 2, 'Con': 3, 'New': 3})\n",
    "\n",
    "    dataset[\"SaleCondition\"] = dataset.SaleCondition.map(\n",
    "        {'AdjLand': 1, 'Abnorml': 2, 'Alloca': 2, 'Family': 2, 'Normal': 3, 'Partial': 4})\n",
    "\n",
    "    dataset[\"Street\"] = dataset.Street.map({'Grvl': 1, 'Pave': 2})\n",
    "\n",
    "    dataset[\"Alley\"] = dataset.Alley.map({'None': 1, 'Grvl': 2, 'Pave': 3})\n",
    "\n",
    "    dataset[\"LotShape\"] = dataset.LotShape.map({'Reg': 1, 'IR1': 2, 'IR2': 3, 'IR3': 4})\n",
    "\n",
    "    dataset[\"LandContour\"] = dataset.LandContour.map({'Bnk': 1, 'Lvl': 2, 'Low': 3, 'HLS': 4})\n",
    "\n",
    "    dataset[\"Utilities\"] = dataset.Utilities.map({'ELO': 1, 'NoSeWa': 2, 'NoSewr': 3, 'AllPub': 4})\n",
    "\n",
    "    dataset[\"LotConfig\"] = dataset.LotConfig.map({'Inside': 1, 'Corner': 2, 'FR2': 3, 'FR3': 4, 'CulDSac': 5})\n",
    "\n",
    "    dataset[\"LandSlope\"] = dataset.LandSlope.map({'Sev': 1, 'Mod': 2, 'Gtl': 3})\n",
    "\n",
    "    dataset[\"Condition1\"] = dataset.Condition1.map(\n",
    "        {'Artery': 1, 'Feedr': 2, 'RRAe': 3, 'Norm': 4, 'RRAn': 5, 'PosN': 6, 'PosA': 7, 'RRNe': 8, 'RRNn': 9})\n",
    "\n",
    "    dataset[\"Condition2\"] = dataset.Condition2.map(\n",
    "        {'Artery': 1, 'Feedr': 2, 'RRAe': 3, 'Norm': 4, 'RRAn': 5, 'PosN': 6, 'PosA': 7, 'RRNe': 8, 'RRNn': 9})\n",
    "\n",
    "    dataset[\"RoofStyle\"] = dataset.RoofStyle.map(\n",
    "        {'Flat': 1, 'Gable': 2, 'Gambrel': 3, 'Hip': 4, 'Mansard': 5, 'Shed': 6})\n",
    "\n",
    "    dataset[\"RoofMatl\"] = dataset.RoofMatl.map(\n",
    "        {'ClyTile': 1, 'CompShg': 2, 'Membran': 3, 'Metal': 4, 'Roll': 5, 'Tar&Grv': 6, 'WdShake': 7, 'WdShngl': 8})\n",
    "\n",
    "    dataset[\"Exterior1st\"] = dataset.Exterior1st.map(\n",
    "        {'AsbShng': 1, 'AsphShn': 2, 'BrkComm': 3, 'BrkFace': 4, 'CBlock': 5, 'CemntBd': 6, 'HdBoard': 7, 'ImStucc': 8,\n",
    "         'MetalSd': 9, 'Other': 10, 'Plywood': 11, 'PreCast': 12, 'Stone': 13, 'Stucco': 14, 'VinylSd': 15,\n",
    "         'Wd Sdng': 16, 'WdShing': 17})\n",
    "\n",
    "    dataset[\"Exterior2nd\"] = dataset.Exterior2nd.map(\n",
    "        {'AsbShng': 1, 'AsphShn': 2, 'Brk Cmn': 3, 'BrkFace': 4, 'CBlock': 5, 'CmentBd': 6, 'HdBoard': 7, 'ImStucc': 8,\n",
    "         'MetalSd': 9, 'Other': 10, 'Plywood': 11, 'PreCast': 12, 'Stone': 13, 'Stucco': 14, 'VinylSd': 15,\n",
    "         'Wd Sdng': 16, 'Wd Shng': 17})\n",
    "\n",
    "    dataset[\"MasVnrType\"] = dataset.MasVnrType.map({'BrkCmn': 1, 'BrkFace': 2, 'CBlock': 3, 'None': 4, 'Stone': 5})\n",
    "\n",
    "    dataset[\"ExterQual\"] = dataset.ExterQual.map({'Ex': 1, 'Gd': 2, 'TA': 3, 'Fa': 4, 'Po': 5})\n",
    "\n",
    "    dataset[\"ExterQual\"] = dataset.ExterQual.map({'Ex': 1, 'Gd': 2, 'TA': 3, 'Fa': 4, 'Po': 5})\n",
    "\n",
    "    dataset[\"ExterCond\"] = dataset.ExterCond.map({'Ex': 1, 'Gd': 2, 'TA': 3, 'Fa': 4, 'Po': 5})\n",
    "\n",
    "    dataset[\"BsmtQual\"] = dataset.BsmtQual.map({'Ex': 1, 'Gd': 2, 'TA': 3, 'Fa': 4, 'Po': 5, 'None': 6})\n",
    "\n",
    "    dataset[\"BsmtCond\"] = dataset.BsmtCond.map({'Ex': 1, 'Gd': 2, 'TA': 3, 'Fa': 4, 'Po': 5, 'None': 6})\n",
    "\n",
    "    dataset[\"BsmtFinType1\"] = dataset.BsmtFinType1.map(\n",
    "        {'GLQ': 1, 'ALQ': 2, 'BLQ': 3, 'Rec': 4, 'LwQ': 5, 'Unf': 6, 'None': 7})\n",
    "\n",
    "    dataset[\"BsmtFinType2\"] = dataset.BsmtFinType2.map(\n",
    "        {'GLQ': 1, 'ALQ': 2, 'BLQ': 3, 'Rec': 4, 'LwQ': 5, 'Unf': 6, 'None': 7})\n",
    "\n",
    "    dataset[\"HeatingQC\"] = dataset.HeatingQC.map({'Ex': 1, 'Gd': 2, 'TA': 3, 'Fa': 4, 'Po': 5})\n",
    "\n",
    "    dataset[\"CentralAir\"] = dataset.CentralAir.map({'N': 0, 'Y': 1})\n",
    "\n",
    "    dataset[\"Electrical\"] = dataset.Electrical.map({'SBrkr': 1, 'FuseA': 2, 'FuseF': 3, 'FuseP': 4, 'Mix': 5})\n",
    "\n",
    "    dataset[\"KitchenQual\"] = dataset.KitchenQual.map({'Ex': 1, 'Gd': 2, 'TA': 3, 'Fa': 4, 'Po': 5})\n",
    "\n",
    "    dataset[\"Functional\"] = dataset.Functional.map(\n",
    "        {'Typ': 1, 'Min1': 2, 'Min2': 3, 'Mod': 4, 'Maj1': 5, 'Maj2': 6, 'Sev': 7, 'Sal': 8})\n",
    "\n",
    "    dataset[\"FireplaceQu\"] = dataset.FireplaceQu.map({'Ex': 1, 'Gd': 2, 'TA': 3, 'Fa': 4, 'Po': 5, 'None': 6})\n",
    "\n",
    "    dataset[\"GarageType\"] = dataset.GarageType.map(\n",
    "        {'2Types': 1, 'Attchd': 2, 'Basment': 3, 'BuiltIn': 4, 'CarPort': 5, 'Detchd': 6, 'None': 7})\n",
    "\n",
    "    dataset[\"GarageFinish\"] = dataset.GarageFinish.map({'Fin': 1, 'RFn': 2, 'Unf': 3, 'None': 4})\n",
    "\n",
    "    dataset[\"GarageQual\"] = dataset.GarageQual.map({'Ex': 1, 'Gd': 2, 'TA': 3, 'Fa': 4, 'Po': 5, 'None': 6})\n",
    "\n",
    "    dataset[\"GarageCond\"] = dataset.GarageCond.map({'Ex': 1, 'Gd': 2, 'TA': 3, 'Fa': 4, 'Po': 5, 'None': 6})\n",
    "\n",
    "    dataset[\"PavedDrive\"] = dataset.PavedDrive.map({'Y': 1, 'P': 2, 'N': 3})\n",
    "\n",
    "    dataset[\"PoolQC\"] = dataset.PoolQC.map({'Ex': 1, 'Gd': 2, 'TA': 3, 'Fa': 4, 'None': 5})\n",
    "\n",
    "    dataset[\"Fence\"] = dataset.Fence.map({'GdPrv': 1, 'MnPrv': 2, 'GdWo': 3, 'MnWw': 4, 'None': 5})\n",
    "\n",
    "    dataset[\"MiscFeature\"] = dataset.MiscFeature.map({'Elev': 1, 'Gar2': 2, 'Othr': 3, 'Shed': 4, 'TenC': 5, 'None': 6})\n",
    "\n",
    "    dataset[\"SaleType\"] = dataset.SaleType.map(\n",
    "        {'WD': 1, 'CWD': 2, 'VWD': 3, 'New': 4, 'COD': 5, 'Con': 6, 'ConLw': 7, 'ConLI': 8, 'ConLD': 9, 'Oth': 10})\n",
    "\n",
    "    dataset[\"SaleCondition\"] = dataset.SaleCondition.map(\n",
    "        {'Normal': 1, 'Abnorml': 2, 'AdjLand': 3, 'Alloca': 4, 'Family': 5, 'Partial': 6})\n",
    "\n",
    "    return dataset\n",
    "\n",
    "\n",
    "dataset_df = map_values(dataset_df)"
   ],
   "id": "c8f4eb44db207ca0",
   "outputs": [],
   "execution_count": 121
  },
  {
   "cell_type": "markdown",
   "source": "Then, we split the dataset into training and validation sets using a `split_dataset` function.\n\nThe ratio of the test set is set to `0.30`.",
   "metadata": {},
   "id": "6a77674359deef9e"
  },
  {
   "cell_type": "code",
   "source": "def split_dataset(dataset, test_ratio=0.30):\n  test_indices = np.random.rand(len(dataset)) < test_ratio\n  return dataset[~test_indices], dataset[test_indices]\n\ntrain_ds_pd, valid_ds_pd = split_dataset(dataset_df)",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-06-26T16:01:21.569335Z",
     "iopub.execute_input": "2024-06-26T16:01:21.570959Z",
     "iopub.status.idle": "2024-06-26T16:01:21.579023Z",
     "shell.execute_reply.started": "2024-06-26T16:01:21.570924Z",
     "shell.execute_reply": "2024-06-26T16:01:21.577878Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-06-27T16:02:34.181706Z",
     "start_time": "2024-06-27T16:02:34.157923Z"
    }
   },
   "id": "4c2c5c98a9f1f2ab",
   "outputs": [],
   "execution_count": 122
  },
  {
   "cell_type": "markdown",
   "source": "The label column is set to `SalePrice` since it is the target column.",
   "metadata": {},
   "id": "289be8cb69f0b0b6"
  },
  {
   "cell_type": "code",
   "source": "label = 'SalePrice'",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-06-26T16:01:21.582444Z",
     "iopub.execute_input": "2024-06-26T16:01:21.582940Z",
     "iopub.status.idle": "2024-06-26T16:01:21.588950Z",
     "shell.execute_reply.started": "2024-06-26T16:01:21.582901Z",
     "shell.execute_reply": "2024-06-26T16:01:21.587646Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-06-27T16:02:34.188089Z",
     "start_time": "2024-06-27T16:02:34.184255Z"
    }
   },
   "id": "dd410b0d4bde1a6f",
   "outputs": [],
   "execution_count": 123
  },
  {
   "cell_type": "markdown",
   "source": "Now, we convert the `pandas` dataframes to `tf.data.Dataset` objects.\n\nThe `tfdf.keras.pd_dataframe_to_tf_dataset` function is used for this purpose.",
   "metadata": {},
   "id": "828762d2bca7a070"
  },
  {
   "cell_type": "code",
   "source": "train_ds = tfdf.keras.pd_dataframe_to_tf_dataset(train_ds_pd, label=label, task=tfdf.keras.Task.REGRESSION)\nvalid_ds = tfdf.keras.pd_dataframe_to_tf_dataset(valid_ds_pd, label=label, task=tfdf.keras.Task.REGRESSION)",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-06-26T16:01:21.590382Z",
     "iopub.execute_input": "2024-06-26T16:01:21.590740Z",
     "iopub.status.idle": "2024-06-26T16:01:21.855031Z",
     "shell.execute_reply.started": "2024-06-26T16:01:21.590710Z",
     "shell.execute_reply": "2024-06-26T16:01:21.853888Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-06-27T16:02:34.716485Z",
     "start_time": "2024-06-27T16:02:34.190503Z"
    }
   },
   "id": "d17857b54d952ef2",
   "outputs": [],
   "execution_count": 124
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-27T16:02:34.946670Z",
     "start_time": "2024-06-27T16:02:34.719697Z"
    }
   },
   "cell_type": "code",
   "source": "X_train, y_train = train_ds.data, train_ds.target",
   "id": "380e499bbd26332c",
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'_PrefetchDataset' object has no attribute 'data'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[125], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m X_train, y_train \u001B[38;5;241m=\u001B[39m \u001B[43mtrain_ds\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdata\u001B[49m, train_ds\u001B[38;5;241m.\u001B[39mtarget\n",
      "\u001B[0;31mAttributeError\u001B[0m: '_PrefetchDataset' object has no attribute 'data'"
     ]
    }
   ],
   "execution_count": 125
  },
  {
   "cell_type": "markdown",
   "source": "Finally, we create a Random Forest model and fit it to the training data.",
   "metadata": {},
   "id": "f4688828e4da25e1"
  },
  {
   "cell_type": "code",
   "source": [
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "params = {\n",
    "    'objective': 'reg:squarederror',\n",
    "    'eval_metric': 'rmse'\n",
    "}\n",
    "\n",
    "bst = xgb.train(params, dtrain)\n",
    "\n",
    "preds = bst.predict(dtrain)\n",
    "\n",
    "print(preds)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-06-26T16:01:21.856364Z",
     "iopub.execute_input": "2024-06-26T16:01:21.856697Z",
     "iopub.status.idle": "2024-06-26T16:01:40.434350Z",
     "shell.execute_reply.started": "2024-06-26T16:01:21.856670Z",
     "shell.execute_reply": "2024-06-26T16:01:40.433158Z"
    },
    "trusted": true
   },
   "id": "8fc976059ea416d8",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": "The model is evaluated on the validation set using the `evaluate` function.",
   "metadata": {},
   "id": "20123bde00f9fab5"
  },
  {
   "cell_type": "code",
   "source": "evaluation = rf.evaluate(valid_ds)",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-06-26T16:01:40.435828Z",
     "iopub.execute_input": "2024-06-26T16:01:40.436211Z",
     "iopub.status.idle": "2024-06-26T16:01:48.361992Z",
     "shell.execute_reply.started": "2024-06-26T16:01:40.436180Z",
     "shell.execute_reply": "2024-06-26T16:01:48.360771Z"
    },
    "trusted": true
   },
   "id": "55b16453d168eae8",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": "The model is then used to make predictions on the test set.",
   "metadata": {},
   "id": "4289ef5596b43ba"
  },
  {
   "cell_type": "code",
   "source": [
    "test_data = pd.read_csv(test_file_path)\n",
    "ids = test_data.pop('Id')\n",
    "\n",
    "test_data = map_values(test_data)\n",
    "\n",
    "test_ds = tfdf.keras.pd_dataframe_to_tf_dataset(\n",
    "    test_data,\n",
    "    task = tfdf.keras.Task.REGRESSION)\n",
    "\n",
    "preds = rf.predict(test_ds)\n",
    "output = pd.DataFrame({'Id': ids,\n",
    "                       'SalePrice': preds.squeeze()})"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-06-26T16:01:48.363724Z",
     "iopub.execute_input": "2024-06-26T16:01:48.364185Z",
     "iopub.status.idle": "2024-06-26T16:01:49.379266Z",
     "shell.execute_reply.started": "2024-06-26T16:01:48.364144Z",
     "shell.execute_reply": "2024-06-26T16:01:49.378160Z"
    },
    "trusted": true
   },
   "id": "52a0f09fe1bc89ba",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": "Finally, the predictions are saved to a CSV file.",
   "metadata": {},
   "id": "31ecbd369941922e"
  },
  {
   "cell_type": "code",
   "source": [
    "# sample_submission_df = pd.read_csv('/kaggle/input/house-prices-advanced-regression-techniques/sample_submission.csv')\n",
    "sample_submission_df = pd.read_csv('data/sample_submission.csv')\n",
    "sample_submission_df['SalePrice'] = rf.predict(test_ds)\n",
    "# sample_submission_df.to_csv('/kaggle/working/submission.csv', index=False)\n",
    "sample_submission_df.to_csv('submission.csv', index=False)\n",
    "sample_submission_df.head()"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-06-26T16:01:49.381293Z",
     "iopub.execute_input": "2024-06-26T16:01:49.381729Z",
     "iopub.status.idle": "2024-06-26T16:01:49.726974Z",
     "shell.execute_reply.started": "2024-06-26T16:01:49.381689Z",
     "shell.execute_reply": "2024-06-26T16:01:49.725924Z"
    },
    "trusted": true
   },
   "id": "585b9fb3a4cf8163",
   "outputs": [],
   "execution_count": null
  }
 ]
}
