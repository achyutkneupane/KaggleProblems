{
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.13",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "sourceId": 5407,
     "databundleVersionId": 868283,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30732,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook",
   "isGpuEnabled": false
  }
 },
 "nbformat_minor": 5,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "markdown",
   "source": "Importing the necessary libraries:\n\n- `tensorflow_decision_forests` for the Random Forest model\n- `pandas` for data manipulation\n- `numpy` for numerical operations",
   "metadata": {},
   "id": "3084be9ecb760e4d"
  },
  {
   "cell_type": "code",
   "source": "import tensorflow_decision_forests as tfdf\nimport pandas as pd\nimport numpy as np",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-06-26T16:01:16.774199Z",
     "iopub.execute_input": "2024-06-26T16:01:16.775383Z",
     "iopub.status.idle": "2024-06-26T16:01:21.526763Z",
     "shell.execute_reply.started": "2024-06-26T16:01:16.775333Z",
     "shell.execute_reply": "2024-06-26T16:01:21.525554Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-06-27T15:36:44.386638Z",
     "start_time": "2024-06-27T15:36:44.380403Z"
    }
   },
   "id": "7468f3ea9736958f",
   "outputs": [],
   "execution_count": 81
  },
  {
   "cell_type": "markdown",
   "source": "First, we load the dataset and remove the `Id` column since it is not useful for the model.",
   "metadata": {},
   "id": "c462d1e612c128de"
  },
  {
   "cell_type": "code",
   "source": [
    "# train_file_path = \"/kaggle/input/house-prices-advanced-regression-techniques/train.csv\"\n",
    "# test_file_path = \"/kaggle/input/house-prices-advanced-regression-techniques/test.csv\"\n",
    "\n",
    "train_file_path = \"data/train.csv\"\n",
    "test_file_path = \"data/test.csv\""
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-06-26T16:01:21.528919Z",
     "iopub.execute_input": "2024-06-26T16:01:21.529537Z",
     "iopub.status.idle": "2024-06-26T16:01:21.567692Z",
     "shell.execute_reply.started": "2024-06-26T16:01:21.529503Z",
     "shell.execute_reply": "2024-06-26T16:01:21.566420Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-06-27T15:36:44.599045Z",
     "start_time": "2024-06-27T15:36:44.596219Z"
    }
   },
   "id": "d2f0f0f098f8a46a",
   "outputs": [],
   "execution_count": 82
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-27T15:36:44.655234Z",
     "start_time": "2024-06-27T15:36:44.617663Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dataset_df = pd.read_csv(train_file_path)\n",
    "dataset_df = dataset_df.drop('Id', axis=1)"
   ],
   "id": "c5ac1d6d8ceac719",
   "outputs": [],
   "execution_count": 83
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-27T15:36:44.664302Z",
     "start_time": "2024-06-27T15:36:44.657452Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dataset_df.drop(\n",
    "    dataset_df[(dataset_df[\"GrLivArea\"] > 4000) & (dataset_df[\"SalePrice\"] < 300000)].index,\n",
    "    inplace=True)"
   ],
   "id": "691b036e786232a4",
   "outputs": [],
   "execution_count": 84
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-27T15:36:44.723706Z",
     "start_time": "2024-06-27T15:36:44.721336Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# dataset_df[\"LotAreaCut\"] = pd.qcut(dataset_df.LotArea, 10)\n",
    "# dataset_df['LotFrontage'] = dataset_df.groupby(['LotAreaCut', 'Neighborhood'])['LotFrontage'].transform(\n",
    "#     lambda x: x.fillna(x.median()))\n",
    "# dataset_df['LotFrontage'] = dataset_df.groupby(['LotAreaCut'])['LotFrontage'].transform(lambda x: x.fillna(x.median()))"
   ],
   "id": "6a7a70953b65109d",
   "outputs": [],
   "execution_count": 85
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-27T15:36:44.813144Z",
     "start_time": "2024-06-27T15:36:44.807641Z"
    }
   },
   "cell_type": "code",
   "source": [
    "area_cols = [\"MasVnrArea\", \"BsmtUnfSF\", \"TotalBsmtSF\", \"GarageCars\", \"BsmtFinSF2\", \"BsmtFinSF1\", \"GarageArea\"]\n",
    "for col in area_cols:\n",
    "    dataset_df[col].fillna(0, inplace=True)"
   ],
   "id": "6308a8abe8791086",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_8/s86gthys1d7dsy7_0r3l3f_m0000gn/T/ipykernel_71761/1906549421.py:3: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  dataset_df[col].fillna(0, inplace=True)\n"
     ]
    }
   ],
   "execution_count": 86
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-27T15:36:44.870250Z",
     "start_time": "2024-06-27T15:36:44.859436Z"
    }
   },
   "cell_type": "code",
   "source": [
    "feature_cols = [\"PoolQC\", \"MiscFeature\", \"Alley\", \"Fence\", \"FireplaceQu\", \"GarageQual\", \"GarageCond\", \"GarageFinish\",\n",
    "                \"GarageYrBlt\", \"GarageType\", \"BsmtExposure\", \"BsmtCond\", \"BsmtQual\", \"BsmtFinType2\", \"BsmtFinType1\",\n",
    "                \"MasVnrType\"]\n",
    "for col in feature_cols:\n",
    "    dataset_df[col].fillna(0, inplace=True)"
   ],
   "id": "755447b03d9c01d9",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_8/s86gthys1d7dsy7_0r3l3f_m0000gn/T/ipykernel_71761/698046458.py:5: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  dataset_df[col].fillna(0, inplace=True)\n"
     ]
    }
   ],
   "execution_count": 87
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-27T15:36:44.982550Z",
     "start_time": "2024-06-27T15:36:44.972326Z"
    }
   },
   "cell_type": "code",
   "source": [
    "number_cols = [\"MSSubClass\", \"BsmtFullBath\", \"BsmtHalfBath\", \"HalfBath\", \"BedroomAbvGr\", \"KitchenAbvGr\", \"MoSold\",\n",
    "               \"YrSold\", \"YearBuilt\", \"YearRemodAdd\", \"LowQualFinSF\", \"GarageYrBlt\"]\n",
    "for col in number_cols:\n",
    "    dataset_df[col] = dataset_df[col].astype(str)"
   ],
   "id": "178578f2c5e378c9",
   "outputs": [],
   "execution_count": 88
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-27T15:36:45.072756Z",
     "start_time": "2024-06-27T15:36:45.018372Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def map_values(dataset):\n",
    "    dataset[\"MSSubClass\"] = dataset.MSSubClass.map({'180': 1,\n",
    "                                                    '30': 2, '45': 2,\n",
    "                                                    '190': 3, '50': 3, '90': 3,\n",
    "                                                    '85': 4, '40': 4, '160': 4,\n",
    "                                                    '70': 5, '20': 5, '75': 5, '80': 5, '150': 5,\n",
    "                                                    '120': 6, '60': 6})\n",
    "\n",
    "    dataset[\"MSZoning\"] = dataset.MSZoning.map({'C (all)': 1, 'RH': 2, 'RM': 2, 'RL': 3, 'FV': 4})\n",
    "\n",
    "    dataset[\"Neighborhood\"] = dataset.Neighborhood.map({'MeadowV': 1,\n",
    "                                                        'IDOTRR': 2, 'BrDale': 2,\n",
    "                                                        'OldTown': 3, 'Edwards': 3, 'BrkSide': 3,\n",
    "                                                        'Sawyer': 4, 'Blueste': 4, 'SWISU': 4, 'NAmes': 4,\n",
    "                                                        'NPkVill': 5, 'Mitchel': 5,\n",
    "                                                        'SawyerW': 6, 'Gilbert': 6, 'NWAmes': 6,\n",
    "                                                        'Blmngtn': 7, 'CollgCr': 7, 'ClearCr': 7, 'Crawfor': 7,\n",
    "                                                        'Veenker': 8, 'Somerst': 8, 'Timber': 8,\n",
    "                                                        'StoneBr': 9,\n",
    "                                                        'NoRidge': 10, 'NridgHt': 10})\n",
    "\n",
    "    dataset[\"Condition1\"] = dataset.Condition1.map({'Artery': 1,\n",
    "                                                    'Feedr': 2, 'RRAe': 2,\n",
    "                                                    'Norm': 3, 'RRAn': 3,\n",
    "                                                    'PosN': 4, 'RRNe': 4,\n",
    "                                                    'PosA': 5, 'RRNn': 5})\n",
    "\n",
    "    dataset[\"BldgType\"] = dataset.BldgType.map({'2fmCon': 1, 'Duplex': 1, 'Twnhs': 1, '1Fam': 2, 'TwnhsE': 2})\n",
    "\n",
    "    dataset[\"HouseStyle\"] = dataset.HouseStyle.map({'1.5Unf': 1,\n",
    "                                                    '1.5Fin': 2, '2.5Unf': 2, 'SFoyer': 2,\n",
    "                                                    '1Story': 3, 'SLvl': 3,\n",
    "                                                    '2Story': 4, '2.5Fin': 4})\n",
    "\n",
    "    dataset[\"Exterior1st\"] = dataset.Exterior1st.map({'BrkComm': 1,\n",
    "                                                      'AsphShn': 2, 'CBlock': 2, 'AsbShng': 2,\n",
    "                                                      'WdShing': 3, 'Wd Sdng': 3, 'MetalSd': 3, 'Stucco': 3,\n",
    "                                                      'HdBoard': 3,\n",
    "                                                      'BrkFace': 4, 'Plywood': 4,\n",
    "                                                      'VinylSd': 5,\n",
    "                                                      'CemntBd': 6,\n",
    "                                                      'Stone': 7, 'ImStucc': 7})\n",
    "\n",
    "    dataset[\"MasVnrType\"] = dataset.MasVnrType.map({'BrkCmn': 1, 'None': 1, 'BrkFace': 2, 'Stone': 3})\n",
    "\n",
    "    dataset[\"ExterQual\"] = dataset.ExterQual.map({'Fa': 1, 'TA': 2, 'Gd': 3, 'Ex': 4})\n",
    "\n",
    "    dataset[\"Foundation\"] = dataset.Foundation.map({'Slab': 1,\n",
    "                                                    'BrkTil': 2, 'CBlock': 2, 'Stone': 2,\n",
    "                                                    'Wood': 3, 'PConc': 4})\n",
    "\n",
    "    dataset[\"BsmtQual\"] = dataset.BsmtQual.map({'Fa': 2, 'None': 1, 'TA': 3, 'Gd': 4, 'Ex': 5})\n",
    "\n",
    "    dataset[\"BsmtExposure\"] = dataset.BsmtExposure.map({'None': 1, 'No': 2, 'Av': 3, 'Mn': 3, 'Gd': 4})\n",
    "\n",
    "    dataset[\"Heating\"] = dataset.Heating.map({'Floor': 1, 'Grav': 1, 'Wall': 2, 'OthW': 3, 'GasW': 4, 'GasA': 5})\n",
    "\n",
    "    dataset[\"HeatingQC\"] = dataset.HeatingQC.map({'Po': 1, 'Fa': 2, 'TA': 3, 'Gd': 4, 'Ex': 5})\n",
    "\n",
    "    dataset[\"KitchenQual\"] = dataset.KitchenQual.map({'Fa': 1, 'TA': 2, 'Gd': 3, 'Ex': 4})\n",
    "\n",
    "    dataset[\"Functional\"] = dataset.Functional.map(\n",
    "        {'Maj2': 1, 'Maj1': 2, 'Min1': 2, 'Min2': 2, 'Mod': 2, 'Sev': 2, 'Typ': 3})\n",
    "\n",
    "    dataset[\"FireplaceQu\"] = dataset.FireplaceQu.map({'None': 1, 'Po': 1, 'Fa': 2, 'TA': 3, 'Gd': 4, 'Ex': 5})\n",
    "\n",
    "    dataset[\"GarageType\"] = dataset.GarageType.map({'CarPort': 1, 'None': 1,\n",
    "                                                    'Detchd': 2,\n",
    "                                                    '2Types': 3, 'Basment': 3,\n",
    "                                                    'Attchd': 4, 'BuiltIn': 5})\n",
    "\n",
    "    dataset[\"GarageFinish\"] = dataset.GarageFinish.map({'None': 1, 'Unf': 2, 'RFn': 3, 'Fin': 4})\n",
    "\n",
    "    dataset[\"PavedDrive\"] = dataset.PavedDrive.map({'N': 1, 'P': 2, 'Y': 3})\n",
    "\n",
    "    dataset[\"SaleType\"] = dataset.SaleType.map({'COD': 1, 'ConLD': 1, 'ConLI': 1, 'ConLw': 1, 'Oth': 1, 'WD': 1,\n",
    "                                                'CWD': 2, 'Con': 3, 'New': 3})\n",
    "\n",
    "    dataset[\"SaleCondition\"] = dataset.SaleCondition.map(\n",
    "        {'AdjLand': 1, 'Abnorml': 2, 'Alloca': 2, 'Family': 2, 'Normal': 3, 'Partial': 4})\n",
    "\n",
    "    dataset[\"Street\"] = dataset.Street.map({'Grvl': 1, 'Pave': 2})\n",
    "\n",
    "    dataset[\"Alley\"] = dataset.Alley.map({'None': 1, 'Grvl': 2, 'Pave': 3})\n",
    "\n",
    "    dataset[\"LotShape\"] = dataset.LotShape.map({'Reg': 1, 'IR1': 2, 'IR2': 3, 'IR3': 4})\n",
    "\n",
    "    dataset[\"LandContour\"] = dataset.LandContour.map({'Bnk': 1, 'Lvl': 2, 'Low': 3, 'HLS': 4})\n",
    "\n",
    "    dataset[\"Utilities\"] = dataset.Utilities.map({'ELO': 1, 'NoSeWa': 2, 'NoSewr': 3, 'AllPub': 4})\n",
    "\n",
    "    dataset[\"LotConfig\"] = dataset.LotConfig.map({'Inside': 1, 'Corner': 2, 'FR2': 3, 'FR3': 4, 'CulDSac': 5})\n",
    "\n",
    "    dataset[\"LandSlope\"] = dataset.LandSlope.map({'Sev': 1, 'Mod': 2, 'Gtl': 3})\n",
    "\n",
    "    dataset[\"Condition1\"] = dataset.Condition1.map(\n",
    "        {'Artery': 1, 'Feedr': 2, 'RRAe': 3, 'Norm': 4, 'RRAn': 5, 'PosN': 6, 'PosA': 7, 'RRNe': 8, 'RRNn': 9})\n",
    "\n",
    "    dataset[\"Condition2\"] = dataset.Condition2.map(\n",
    "        {'Artery': 1, 'Feedr': 2, 'RRAe': 3, 'Norm': 4, 'RRAn': 5, 'PosN': 6, 'PosA': 7, 'RRNe': 8, 'RRNn': 9})\n",
    "\n",
    "    dataset[\"RoofStyle\"] = dataset.RoofStyle.map(\n",
    "        {'Flat': 1, 'Gable': 2, 'Gambrel': 3, 'Hip': 4, 'Mansard': 5, 'Shed': 6})\n",
    "\n",
    "    dataset[\"RoofMatl\"] = dataset.RoofMatl.map(\n",
    "        {'ClyTile': 1, 'CompShg': 2, 'Membran': 3, 'Metal': 4, 'Roll': 5, 'Tar&Grv': 6, 'WdShake': 7, 'WdShngl': 8})\n",
    "\n",
    "    dataset[\"Exterior1st\"] = dataset.Exterior1st.map(\n",
    "        {'AsbShng': 1, 'AsphShn': 2, 'BrkComm': 3, 'BrkFace': 4, 'CBlock': 5, 'CemntBd': 6, 'HdBoard': 7, 'ImStucc': 8,\n",
    "         'MetalSd': 9, 'Other': 10, 'Plywood': 11, 'PreCast': 12, 'Stone': 13, 'Stucco': 14, 'VinylSd': 15,\n",
    "         'Wd Sdng': 16, 'WdShing': 17})\n",
    "\n",
    "    dataset[\"Exterior2nd\"] = dataset.Exterior2nd.map(\n",
    "        {'AsbShng': 1, 'AsphShn': 2, 'Brk Cmn': 3, 'BrkFace': 4, 'CBlock': 5, 'CmentBd': 6, 'HdBoard': 7, 'ImStucc': 8,\n",
    "         'MetalSd': 9, 'Other': 10, 'Plywood': 11, 'PreCast': 12, 'Stone': 13, 'Stucco': 14, 'VinylSd': 15,\n",
    "         'Wd Sdng': 16, 'Wd Shng': 17})\n",
    "\n",
    "    dataset[\"MasVnrType\"] = dataset.MasVnrType.map({'BrkCmn': 1, 'BrkFace': 2, 'CBlock': 3, 'None': 4, 'Stone': 5})\n",
    "\n",
    "    dataset[\"ExterQual\"] = dataset.ExterQual.map({'Ex': 1, 'Gd': 2, 'TA': 3, 'Fa': 4, 'Po': 5})\n",
    "\n",
    "    dataset[\"ExterQual\"] = dataset.ExterQual.map({'Ex': 1, 'Gd': 2, 'TA': 3, 'Fa': 4, 'Po': 5})\n",
    "\n",
    "    dataset[\"ExterCond\"] = dataset.ExterCond.map({'Ex': 1, 'Gd': 2, 'TA': 3, 'Fa': 4, 'Po': 5})\n",
    "\n",
    "    dataset[\"BsmtQual\"] = dataset.BsmtQual.map({'Ex': 1, 'Gd': 2, 'TA': 3, 'Fa': 4, 'Po': 5, 'None': 6})\n",
    "\n",
    "    dataset[\"BsmtCond\"] = dataset.BsmtCond.map({'Ex': 1, 'Gd': 2, 'TA': 3, 'Fa': 4, 'Po': 5, 'None': 6})\n",
    "\n",
    "    dataset[\"BsmtFinType1\"] = dataset.BsmtFinType1.map(\n",
    "        {'GLQ': 1, 'ALQ': 2, 'BLQ': 3, 'Rec': 4, 'LwQ': 5, 'Unf': 6, 'None': 7})\n",
    "\n",
    "    dataset[\"BsmtFinType2\"] = dataset.BsmtFinType2.map(\n",
    "        {'GLQ': 1, 'ALQ': 2, 'BLQ': 3, 'Rec': 4, 'LwQ': 5, 'Unf': 6, 'None': 7})\n",
    "\n",
    "    dataset[\"HeatingQC\"] = dataset.HeatingQC.map({'Ex': 1, 'Gd': 2, 'TA': 3, 'Fa': 4, 'Po': 5})\n",
    "\n",
    "    dataset[\"CentralAir\"] = dataset.CentralAir.map({'N': 0, 'Y': 1})\n",
    "\n",
    "    dataset[\"Electrical\"] = dataset.Electrical.map({'SBrkr': 1, 'FuseA': 2, 'FuseF': 3, 'FuseP': 4, 'Mix': 5})\n",
    "\n",
    "    dataset[\"KitchenQual\"] = dataset.KitchenQual.map({'Ex': 1, 'Gd': 2, 'TA': 3, 'Fa': 4, 'Po': 5})\n",
    "\n",
    "    dataset[\"Functional\"] = dataset.Functional.map(\n",
    "        {'Typ': 1, 'Min1': 2, 'Min2': 3, 'Mod': 4, 'Maj1': 5, 'Maj2': 6, 'Sev': 7, 'Sal': 8})\n",
    "\n",
    "    dataset[\"FireplaceQu\"] = dataset.FireplaceQu.map({'Ex': 1, 'Gd': 2, 'TA': 3, 'Fa': 4, 'Po': 5, 'None': 6})\n",
    "\n",
    "    dataset[\"GarageType\"] = dataset.GarageType.map(\n",
    "        {'2Types': 1, 'Attchd': 2, 'Basment': 3, 'BuiltIn': 4, 'CarPort': 5, 'Detchd': 6, 'None': 7})\n",
    "\n",
    "    dataset[\"GarageFinish\"] = dataset.GarageFinish.map({'Fin': 1, 'RFn': 2, 'Unf': 3, 'None': 4})\n",
    "\n",
    "    dataset[\"GarageQual\"] = dataset.GarageQual.map({'Ex': 1, 'Gd': 2, 'TA': 3, 'Fa': 4, 'Po': 5, 'None': 6})\n",
    "\n",
    "    dataset[\"GarageCond\"] = dataset.GarageCond.map({'Ex': 1, 'Gd': 2, 'TA': 3, 'Fa': 4, 'Po': 5, 'None': 6})\n",
    "\n",
    "    dataset[\"PavedDrive\"] = dataset.PavedDrive.map({'Y': 1, 'P': 2, 'N': 3})\n",
    "\n",
    "    dataset[\"PoolQC\"] = dataset.PoolQC.map({'Ex': 1, 'Gd': 2, 'TA': 3, 'Fa': 4, 'None': 5})\n",
    "\n",
    "    dataset[\"Fence\"] = dataset.Fence.map({'GdPrv': 1, 'MnPrv': 2, 'GdWo': 3, 'MnWw': 4, 'None': 5})\n",
    "\n",
    "    dataset[\"MiscFeature\"] = dataset.MiscFeature.map({'Elev': 1, 'Gar2': 2, 'Othr': 3, 'Shed': 4, 'TenC': 5, 'None': 6})\n",
    "\n",
    "    dataset[\"SaleType\"] = dataset.SaleType.map(\n",
    "        {'WD': 1, 'CWD': 2, 'VWD': 3, 'New': 4, 'COD': 5, 'Con': 6, 'ConLw': 7, 'ConLI': 8, 'ConLD': 9, 'Oth': 10})\n",
    "\n",
    "    dataset[\"SaleCondition\"] = dataset.SaleCondition.map(\n",
    "        {'Normal': 1, 'Abnorml': 2, 'AdjLand': 3, 'Alloca': 4, 'Family': 5, 'Partial': 6})\n",
    "\n",
    "    return dataset\n",
    "\n",
    "\n",
    "dataset_df = map_values(dataset_df)"
   ],
   "id": "c8f4eb44db207ca0",
   "outputs": [],
   "execution_count": 89
  },
  {
   "cell_type": "markdown",
   "source": "Then, we split the dataset into training and validation sets using a `split_dataset` function.\n\nThe ratio of the test set is set to `0.30`.",
   "metadata": {},
   "id": "6a77674359deef9e"
  },
  {
   "cell_type": "code",
   "source": "def split_dataset(dataset, test_ratio=0.30):\n  test_indices = np.random.rand(len(dataset)) < test_ratio\n  return dataset[~test_indices], dataset[test_indices]\n\ntrain_ds_pd, valid_ds_pd = split_dataset(dataset_df)",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-06-26T16:01:21.569335Z",
     "iopub.execute_input": "2024-06-26T16:01:21.570959Z",
     "iopub.status.idle": "2024-06-26T16:01:21.579023Z",
     "shell.execute_reply.started": "2024-06-26T16:01:21.570924Z",
     "shell.execute_reply": "2024-06-26T16:01:21.577878Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-06-27T15:36:45.137965Z",
     "start_time": "2024-06-27T15:36:45.129335Z"
    }
   },
   "id": "4c2c5c98a9f1f2ab",
   "outputs": [],
   "execution_count": 90
  },
  {
   "cell_type": "markdown",
   "source": "The label column is set to `SalePrice` since it is the target column.",
   "metadata": {},
   "id": "289be8cb69f0b0b6"
  },
  {
   "cell_type": "code",
   "source": "label = 'SalePrice'",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-06-26T16:01:21.582444Z",
     "iopub.execute_input": "2024-06-26T16:01:21.582940Z",
     "iopub.status.idle": "2024-06-26T16:01:21.588950Z",
     "shell.execute_reply.started": "2024-06-26T16:01:21.582901Z",
     "shell.execute_reply": "2024-06-26T16:01:21.587646Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-06-27T15:36:45.193472Z",
     "start_time": "2024-06-27T15:36:45.189991Z"
    }
   },
   "id": "dd410b0d4bde1a6f",
   "outputs": [],
   "execution_count": 91
  },
  {
   "cell_type": "markdown",
   "source": "Now, we convert the `pandas` dataframes to `tf.data.Dataset` objects.\n\nThe `tfdf.keras.pd_dataframe_to_tf_dataset` function is used for this purpose.",
   "metadata": {},
   "id": "828762d2bca7a070"
  },
  {
   "cell_type": "code",
   "source": "train_ds = tfdf.keras.pd_dataframe_to_tf_dataset(train_ds_pd, label=label, task=tfdf.keras.Task.REGRESSION)\nvalid_ds = tfdf.keras.pd_dataframe_to_tf_dataset(valid_ds_pd, label=label, task=tfdf.keras.Task.REGRESSION)",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-06-26T16:01:21.590382Z",
     "iopub.execute_input": "2024-06-26T16:01:21.590740Z",
     "iopub.status.idle": "2024-06-26T16:01:21.855031Z",
     "shell.execute_reply.started": "2024-06-26T16:01:21.590710Z",
     "shell.execute_reply": "2024-06-26T16:01:21.853888Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-06-27T15:36:45.477588Z",
     "start_time": "2024-06-27T15:36:45.327637Z"
    }
   },
   "id": "d17857b54d952ef2",
   "outputs": [],
   "execution_count": 92
  },
  {
   "cell_type": "markdown",
   "source": "Finally, we create a Random Forest model and fit it to the training data.",
   "metadata": {},
   "id": "f4688828e4da25e1"
  },
  {
   "cell_type": "code",
   "source": "rf = tfdf.keras.RandomForestModel(task = tfdf.keras.Task.REGRESSION)\nrf.compile(metrics=[\"mse\"])\n\nrf.fit(x=train_ds)",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-06-26T16:01:21.856364Z",
     "iopub.execute_input": "2024-06-26T16:01:21.856697Z",
     "iopub.status.idle": "2024-06-26T16:01:40.434350Z",
     "shell.execute_reply.started": "2024-06-26T16:01:21.856670Z",
     "shell.execute_reply": "2024-06-26T16:01:40.433158Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-06-27T15:36:50.971642Z",
     "start_time": "2024-06-27T15:36:45.478986Z"
    }
   },
   "id": "8fc976059ea416d8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use /var/folders/_8/s86gthys1d7dsy7_0r3l3f_m0000gn/T/tmpdb8qa6_q as temporary training directory\n",
      "Reading training dataset...\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function CoreModel._consumes_training_examples_until_eof at 0x167550a40> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function CoreModel._consumes_training_examples_until_eof at 0x167550a40> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset read in 0:00:01.242882. Found 1038 examples.\n",
      "Training model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 24-06-27 21:21:48.8116 +0545 kernel.cc:1233] Loading model from path /var/folders/_8/s86gthys1d7dsy7_0r3l3f_m0000gn/T/tmpdb8qa6_q/model/ with prefix 38bfe09430704876\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model trained in 0:00:02.543623\n",
      "Compiling model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 24-06-27 21:21:49.2647 +0545 decision_forest.cc:734] Model loaded with 300 root(s), 99018 node(s), and 60 input feature(s).\n",
      "[INFO 24-06-27 21:21:49.2649 +0545 abstract_model.cc:1344] Engine \"RandomForestGeneric\" built\n",
      "[INFO 24-06-27 21:21:49.2651 +0545 kernel.cc:1061] Use fast generic engine\n",
      "WARNING:absl:Registering feature \"Condition1\" not used by the model.\n",
      "WARNING:absl:Registering feature \"Exterior1st\" not used by the model.\n",
      "WARNING:absl:Registering feature \"MasVnrType\" not used by the model.\n",
      "WARNING:absl:Registering feature \"ExterQual\" not used by the model.\n",
      "WARNING:absl:Registering feature \"BsmtQual\" not used by the model.\n",
      "WARNING:absl:Registering feature \"HeatingQC\" not used by the model.\n",
      "WARNING:absl:Registering feature \"KitchenQual\" not used by the model.\n",
      "WARNING:absl:Registering feature \"Functional\" not used by the model.\n",
      "WARNING:absl:Registering feature \"FireplaceQu\" not used by the model.\n",
      "WARNING:absl:Registering feature \"GarageType\" not used by the model.\n",
      "WARNING:absl:Registering feature \"GarageFinish\" not used by the model.\n",
      "WARNING:absl:Registering feature \"PavedDrive\" not used by the model.\n",
      "WARNING:absl:Registering feature \"SaleType\" not used by the model.\n",
      "WARNING:absl:Registering feature \"SaleCondition\" not used by the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model compiled.\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function InferenceCoreModel.yggdrasil_model_path_tensor at 0x30a5b0360> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function InferenceCoreModel.yggdrasil_model_path_tensor at 0x30a5b0360> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf_keras.src.callbacks.History at 0x30b446810>"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 93
  },
  {
   "cell_type": "markdown",
   "source": "The model is evaluated on the validation set using the `evaluate` function.",
   "metadata": {},
   "id": "20123bde00f9fab5"
  },
  {
   "cell_type": "code",
   "source": "evaluation = rf.evaluate(valid_ds)",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-06-26T16:01:40.435828Z",
     "iopub.execute_input": "2024-06-26T16:01:40.436211Z",
     "iopub.status.idle": "2024-06-26T16:01:48.361992Z",
     "shell.execute_reply.started": "2024-06-26T16:01:40.436180Z",
     "shell.execute_reply": "2024-06-26T16:01:48.360771Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-06-27T15:36:51.358627Z",
     "start_time": "2024-06-27T15:36:50.974764Z"
    }
   },
   "id": "55b16453d168eae8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function InferenceCoreModel.make_test_function.<locals>.test_function at 0x30a37b600> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function InferenceCoreModel.make_test_function.<locals>.test_function at 0x30a37b600> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 374ms/step - loss: 0.0000e+00 - mse: 1065827392.0000\n"
     ]
    }
   ],
   "execution_count": 94
  },
  {
   "cell_type": "markdown",
   "source": "The model is then used to make predictions on the test set.",
   "metadata": {},
   "id": "4289ef5596b43ba"
  },
  {
   "cell_type": "code",
   "source": [
    "test_data = pd.read_csv(test_file_path)\n",
    "ids = test_data.pop('Id')\n",
    "\n",
    "test_data = map_values(test_data)\n",
    "\n",
    "test_ds = tfdf.keras.pd_dataframe_to_tf_dataset(\n",
    "    test_data,\n",
    "    task = tfdf.keras.Task.REGRESSION)\n",
    "\n",
    "preds = rf.predict(test_ds)\n",
    "output = pd.DataFrame({'Id': ids,\n",
    "                       'SalePrice': preds.squeeze()})"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-06-26T16:01:48.363724Z",
     "iopub.execute_input": "2024-06-26T16:01:48.364185Z",
     "iopub.status.idle": "2024-06-26T16:01:49.379266Z",
     "shell.execute_reply.started": "2024-06-26T16:01:48.364144Z",
     "shell.execute_reply": "2024-06-26T16:01:49.378160Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-06-27T15:36:52.034817Z",
     "start_time": "2024-06-27T15:36:51.359755Z"
    }
   },
   "id": "52a0f09fe1bc89ba",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Registering feature \"Condition1\" not used by the model.\n",
      "WARNING:absl:Registering feature \"Exterior1st\" not used by the model.\n",
      "WARNING:absl:Registering feature \"MasVnrType\" not used by the model.\n",
      "WARNING:absl:Registering feature \"ExterQual\" not used by the model.\n",
      "WARNING:absl:Registering feature \"BsmtQual\" not used by the model.\n",
      "WARNING:absl:Registering feature \"HeatingQC\" not used by the model.\n",
      "WARNING:absl:Registering feature \"KitchenQual\" not used by the model.\n",
      "WARNING:absl:Registering feature \"Functional\" not used by the model.\n",
      "WARNING:absl:Registering feature \"FireplaceQu\" not used by the model.\n",
      "WARNING:absl:Registering feature \"GarageType\" not used by the model.\n",
      "WARNING:absl:Registering feature \"GarageFinish\" not used by the model.\n",
      "WARNING:absl:Registering feature \"PavedDrive\" not used by the model.\n",
      "WARNING:absl:Registering feature \"SaleType\" not used by the model.\n",
      "WARNING:absl:Registering feature \"SaleCondition\" not used by the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 1s 36ms/step\n"
     ]
    }
   ],
   "execution_count": 95
  },
  {
   "cell_type": "markdown",
   "source": "Finally, the predictions are saved to a CSV file.",
   "metadata": {},
   "id": "31ecbd369941922e"
  },
  {
   "cell_type": "code",
   "source": [
    "# sample_submission_df = pd.read_csv('/kaggle/input/house-prices-advanced-regression-techniques/sample_submission.csv')\n",
    "sample_submission_df = pd.read_csv('data/sample_submission.csv')\n",
    "sample_submission_df['SalePrice'] = rf.predict(test_ds)\n",
    "# sample_submission_df.to_csv('/kaggle/working/submission.csv', index=False)\n",
    "sample_submission_df.to_csv('submission.csv', index=False)\n",
    "sample_submission_df.head()"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-06-26T16:01:49.381293Z",
     "iopub.execute_input": "2024-06-26T16:01:49.381729Z",
     "iopub.status.idle": "2024-06-26T16:01:49.726974Z",
     "shell.execute_reply.started": "2024-06-26T16:01:49.381689Z",
     "shell.execute_reply": "2024-06-26T16:01:49.725924Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-06-27T15:36:52.356778Z",
     "start_time": "2024-06-27T15:36:52.037205Z"
    }
   },
   "id": "585b9fb3a4cf8163",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 33ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "     Id      SalePrice\n",
       "0  1461  124141.351562\n",
       "1  1462  137821.375000\n",
       "2  1463  172420.140625\n",
       "3  1464  168157.453125\n",
       "4  1465  190854.906250"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1461</td>\n",
       "      <td>124141.351562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1462</td>\n",
       "      <td>137821.375000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1463</td>\n",
       "      <td>172420.140625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1464</td>\n",
       "      <td>168157.453125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1465</td>\n",
       "      <td>190854.906250</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 96
  }
 ]
}
