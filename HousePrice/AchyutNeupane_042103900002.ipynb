{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Importing the necessary libraries:\n",
    "\n",
    "- `tensorflow_decision_forests` for the Random Forest model\n",
    "- `pandas` for data manipulation\n",
    "- `numpy` for numerical operations"
   ],
   "id": "6f4161359c4570be"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import tensorflow_decision_forests as tfdf\n",
    "import pandas as pd\n",
    "import numpy as np"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "First, we load the dataset",
   "id": "8e6529a4c791501d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "train_file_path = \"/kaggle/input/house-prices-advanced-regression-techniques/train.csv\"\n",
    "test_file_path = \"/kaggle/input/house-prices-advanced-regression-techniques/test.csv\"\n",
    "\n",
    "# train_file_path = \"data/train.csv\"\n",
    "# test_file_path = \"data/test.csv\""
   ],
   "id": "71a2df164487a991",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Now, we load the train dataset and test dataset into a pandas DataFrame and drop the `Id` column",
   "id": "adbc1196eb79231d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "dataset_df = pd.read_csv(train_file_path)\n",
    "test_data = pd.read_csv(test_file_path)\n",
    "\n",
    "dataset_df = dataset_df.drop('Id', axis=1)"
   ],
   "id": "903be3803caea06f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Then, we split the dataset into training and validation sets using a `split_dataset` function.\n",
    "\n",
    "The ratio of the test set is set to `0.30`."
   ],
   "id": "99449d87e9889954"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def split_dataset(dataset, test_ratio=0.30):\n",
    "  test_indices = np.random.rand(len(dataset)) < test_ratio\n",
    "  return dataset[~test_indices], dataset[test_indices]\n",
    "\n",
    "train_ds_pd, valid_ds_pd = split_dataset(dataset_df)"
   ],
   "id": "b8f79f65ca5cb40",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "The label column is set to `SalePrice` since it is the target column.",
   "id": "cb7113bdac88f647"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "label = 'SalePrice'",
   "id": "7da363e8a81794e0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Now, we convert the `pandas` dataframes to `tf.data.Dataset` objects.\n",
    "\n",
    "The `tfdf.keras.pd_dataframe_to_tf_dataset` function is used for this purpose."
   ],
   "id": "d240ce4eeb4a18ee"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "train_ds = tfdf.keras.pd_dataframe_to_tf_dataset(train_ds_pd, label=label, task=tfdf.keras.Task.REGRESSION)\n",
    "valid_ds = tfdf.keras.pd_dataframe_to_tf_dataset(valid_ds_pd, label=label, task=tfdf.keras.Task.REGRESSION)\n",
    "\n",
    "test_ds = tfdf.keras.pd_dataframe_to_tf_dataset(test_data, task = tfdf.keras.Task.REGRESSION)"
   ],
   "id": "57a50c3c494814cb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Finally, we create a Gradient Boosted Trees model and fit it to the training data.",
   "id": "354cde06814b1abd"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "model = tfdf.keras.GradientBoostedTreesModel(task = tfdf.keras.Task.REGRESSION)\n",
    "model.compile(metrics=[\"mse\"])\n",
    "\n",
    "model.fit(x=train_ds)"
   ],
   "id": "692a17f7ecdff838",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "The model is then used to make predictions on the test set.",
   "id": "c4430e6df30ac00c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "predictions = model.predict(test_ds)",
   "id": "868e4c143b0116f2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Finally, the predictions are saved to a CSV file.",
   "id": "aa1fbcaf4cd64dae"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "sample_submission_df = pd.read_csv('/kaggle/input/house-prices-advanced-regression-techniques/sample_submission.csv')\n",
    "# sample_submission_df = pd.read_csv('data/sample_submission.csv')\n",
    "sample_submission_df['SalePrice'] = predictions\n",
    "sample_submission_df.to_csv('/kaggle/working/submission.csv', index=False)\n",
    "# sample_submission_df.to_csv('submission.csv', index=False)\n",
    "sample_submission_df.head()"
   ],
   "id": "8a5caf4acf6af5c2",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
